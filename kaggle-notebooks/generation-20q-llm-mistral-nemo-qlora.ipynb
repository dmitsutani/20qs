{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4c379b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-08T19:52:51.648499Z",
     "iopub.status.busy": "2024-08-08T19:52:51.647711Z",
     "iopub.status.idle": "2024-08-08T19:53:48.712193Z",
     "shell.execute_reply": "2024-08-08T19:53:48.710874Z"
    },
    "papermill": {
     "duration": 57.073959,
     "end_time": "2024-08-08T19:53:48.714794",
     "exception": false,
     "start_time": "2024-08-08T19:52:51.640835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -U \"transformers>=4.42.3\" \n",
    "!pip install -U \"bitsandbytes>0.42.1\" \n",
    "!pip install accelerate peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edf8ce",
   "metadata": {
    "papermill": {
     "duration": 0.004507,
     "end_time": "2024-08-08T19:53:48.724470",
     "exception": false,
     "start_time": "2024-08-08T19:53:48.719963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load model and add LoRA weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5744a8b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:53:48.735694Z",
     "iopub.status.busy": "2024-08-08T19:53:48.735313Z",
     "iopub.status.idle": "2024-08-08T19:55:52.930487Z",
     "shell.execute_reply": "2024-08-08T19:55:52.929610Z"
    },
    "papermill": {
     "duration": 124.203813,
     "end_time": "2024-08-08T19:55:52.933115",
     "exception": false,
     "start_time": "2024-08-08T19:53:48.729302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 19:53:56.801558: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-08 19:53:56.801758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-08 19:53:56.929750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Unused kwargs: ['bnb_4bit_quanty_type', 'bnb_4bit_use_double_quanty']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/quantizers/auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634cb031d3d647518caff21eed5d0025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizerBase\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name = \"/kaggle/input/mistral-nemo-12b-4-bit/transformers/instruction-tuned/1/Mistral-Nemo-Instruct-12b-4bit\"\n",
    "    lora_dir = \"/kaggle/input/20q-mistral-nemo-lora-adapters/transformers/default/4/lora_adapters_final_600_games/checkpoint-7437\"\n",
    "    max_length = 2048\n",
    "    batch_size = 1\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False  \n",
    "    spread_max_length = False  \n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, add_bos_token = True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quanty_type = \"fp4\", \n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quanty = True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    torch_dtype = torch.float16,\n",
    "    device_map = \"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    "    trust_remote_code = True,\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, cfg.lora_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384a126",
   "metadata": {
    "papermill": {
     "duration": 0.005338,
     "end_time": "2024-08-08T19:55:52.944337",
     "exception": false,
     "start_time": "2024-08-08T19:55:52.938999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Functions to format a game (class obs) for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3100c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:55:52.957463Z",
     "iopub.status.busy": "2024-08-08T19:55:52.956762Z",
     "iopub.status.idle": "2024-08-08T19:55:52.988689Z",
     "shell.execute_reply": "2024-08-08T19:55:52.987761Z"
    },
    "papermill": {
     "duration": 0.041118,
     "end_time": "2024-08-08T19:55:52.990737",
     "exception": false,
     "start_time": "2024-08-08T19:55:52.949619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class obs(object):\n",
    "    def __init__(self, keyword, questions, answers, turnType, category):\n",
    "        self.turnType = turnType\n",
    "        self.keyword = keyword\n",
    "        self.category = category\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "\n",
    "import re\n",
    "\n",
    "class MistralPromptFormatter:\n",
    "    def __init__(self, inference_mode = True):\n",
    "        self.sys_prompt = \"You are an AI assistant playing the 20 Questions game. In this game the Answerer is given a secret keyword. \"\\\n",
    "        \"The Questioner then asks yes-or-no questions regarding the keyword, and the Answerer answers them accurately. \"\\\n",
    "        \"Then the Guesser tries to guess the keyword based on the questions and answers in the game.\\n\"\n",
    "        self.inference_mode = inference_mode\n",
    "        \n",
    "    def format_instruction(self, instruction):\n",
    "        return f\"[INST]{instruction}[/INST]\"\n",
    "    \n",
    "    def format_obs(self, obs, guesses):\n",
    "        if obs.turnType == 'ask':\n",
    "            return self.ask_format(obs,guesses)\n",
    "        if obs.turnType == 'answer':\n",
    "            return self.answer_format(obs,guesses)\n",
    "        if obs.turnType == 'guess':\n",
    "            return self.guess_format(obs, guesses)\n",
    "    \n",
    "    def game_to_string(self, obs):\n",
    "        game_string = \"\"\n",
    "        for question, answer in zip(obs.questions, obs.answers):\n",
    "            game_string += f\"Question: {question}\\nAnswer:{answer}\\n\"\n",
    "        print(game_string)\n",
    "        return game_string\n",
    "        \n",
    "    def summarizer_format(self, obs):\n",
    "        sum_prompt = (\"You are an AI assistant for the 20 Questions game. In this game the Answerer is given a secret keyword. \"\n",
    "                      \"The Questioner then asks yes-or-no questions regarding the keyword, and the Answerer answers them accurately. \"\n",
    "                      \"Then the Guesser tries to guess the keyword based on the questions and answers in the game. \"\n",
    "                      \"You are assisting the game by summarizing the information the Questioner has obtained about the keyword from his questions and the Answerer's answers. \"\n",
    "                      \"When prompted, read all questions and answers that are given to you and give a straightforward and concise summary of the information in the game so far. \"\n",
    "                      \"The keyword is a specific thing, NOT a place and NOT a person. \\n\\n\"\n",
    "                      \"Here are all the questions and answers regarding the keyword in the game so far:\\n\" + self.game_to_string(obs) + \"\\nNow write a summary of what is known \"\n",
    "                      \"about the keyword based on the ALL questions and answers above. Include information from all questions and answers above.\"\n",
    "                      \"\\nOpt to say the keyword is a thing, as opposed to an object.\\n Summary:\")\n",
    "        formatted_conversation = self.format_instruction(sum_prompt)\n",
    "        return formatted_conversation\n",
    "        \n",
    "    def ask_format(self, obs, guesses):\n",
    "        ask_prompt = (\"You are playing this game as the Questioner. Ask yes-or-no questions that narrow down what the keyword could be. The keyword is a specific thing, NOT a place and NOT a person. \"\n",
    "                      \"DO NOT ask if the keyword is a specific thing, rather ask something about the keyword, as in the following examples:\\n\"\n",
    "                      \"Example 1: Do NOT ask: 'Is the keyword knife?', INSTEAD ask: 'Is it a knife used for a particular purpose?'\\n\"\n",
    "                      \"Example 2: Do NOT ask: 'Is the keyword cow?', INSTEAD ask: 'Is it a specific type or breed of cow?'\\n\"\n",
    "                      \"Example 3: Do NOT ask: 'Is it bottle?', INSTEAD ask: 'Is it a bottle made of a specific material?'\\n\"\n",
    "                      \"Example 4: Do NOT ask: 'Is the keyword lamp?', INSTEAD ask: 'Is it a type of lamp?'\\n\"\n",
    "                      \"Do NOT assume the game has ended, the game will determine when to stop. Instead keep asking questions about the keyword. \"\n",
    "                      \"Do not output any text other than the question. Start with broad questions \"\n",
    "                      \"and based on the answers so far narrow down your questions. Now ask your first question.\\n\\nQuestion: \")\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt + ask_prompt) \n",
    "        for i in range(len(obs.questions)):\n",
    "            formatted_conversation += obs.questions[i] + \"</s>\"\n",
    "            if self.inference_mode or i != len(obs.questions)-1: \n",
    "                formatted_conversation += '\\n' + self.format_instruction(f\"Answer: {obs.answers[i]}\\nAsk your next question.\\nQuestion:\")  \n",
    "        return formatted_conversation.strip()\n",
    "    \n",
    "    def guess_format(self, obs, guesses):\n",
    "        guess_prompt = \"You are playing this game as the Guesser. After each question and answer you will guess what the keyword is based on the knowledge you have gained \"\\\n",
    "        \"from the questions and answers about the keyword. Do NOT give repeated guesses.\\n\\nRound 1:\\nQuestion: \" + obs.questions[0]+'\\nAnswer: '+ obs.answers[0] +\".\\nNow guess the keyword.\"\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt + guess_prompt) \n",
    "        for i in range(len(guesses)):\n",
    "            formatted_conversation += guesses[i] + \"</s>\"\n",
    "            if self.inference_mode or i < len(guesses)-1: \n",
    "                formatted_conversation += '\\n' + self.format_instruction(f\"Round {i+2}: \\nQuestion: \"+obs.questions[i+1]+\"\\nAnswer: \"+obs.answers[i+1]+\".\\n\"\n",
    "                                                                         \"Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\\nGuess:\")  \n",
    "        return formatted_conversation.strip()\n",
    "    \n",
    "    def answer_format(self, obs, guesses):\n",
    "        answer_prompt = \"You are playing this game as the Answerer. You will answer accurately the questions regarding the keyword with ONLY yes or no. \"\\\n",
    "        \"If the questioner did not ask a question, simply answer 'yes'. \"\\\n",
    "        f\"For this game the keyword is {obs.keyword}. Now answer the question about the keyword.\\nKeyword: {obs.keyword}.\\nQuestion: \" + obs.questions[0] +\"\\nAnswer:\"\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt + answer_prompt) \n",
    "        for i in range(len(obs.answers)):\n",
    "            formatted_conversation += obs.answers[i] + \"</s>\"\n",
    "            if i != len(obs.questions)-1: \n",
    "                formatted_conversation += '\\n' + self.format_instruction(f\"Answer the following question about the keyword.\\nKeyword: {obs.keyword}. \\nQuestion: \" + obs.questions[i+1]+\"\\nAnswer:\")  \n",
    "        return formatted_conversation.strip()\n",
    "    \n",
    "    def format_response(self, string, string_len, obs):\n",
    "        response = string[string_len+3:]\n",
    "        response = response.replace('</s>', '')\n",
    "        if obs.turnType in ['guess', 'ask']:\n",
    "            return response\n",
    "        else:\n",
    "            response = response.lower()\n",
    "            if 'yes' in response: \n",
    "                return \"yes\"\n",
    "            elif 'no' in response: \n",
    "                return \"no\"\n",
    "            else: \n",
    "                return \"yes\"\n",
    "            \n",
    "    def get_guess_variants(self, guess):\n",
    "        trimmed_string = guess.lstrip()\n",
    "        if not trimmed_string:\n",
    "            return []\n",
    "        if not trimmed_string[0].isalpha():\n",
    "            return []\n",
    "        uppercase_version = trimmed_string.capitalize()\n",
    "        lowercase_version = trimmed_string[0].lower() + trimmed_string[1:]  \n",
    "        return [uppercase_version, lowercase_version]\n",
    "\n",
    "formatter = MistralPromptFormatter(inference_mode = True)\n",
    "\n",
    "\n",
    "#################\n",
    "# Define main function to call model and generate response\n",
    "\n",
    "def get_words_ids(words):\n",
    "    return [tokenizer.encode(word, add_special_tokens=False) for word in words]\n",
    "\n",
    "def tokenize(game_text, tokenizer):\n",
    "    return tokenizer(game_text, return_tensors=\"pt\")\n",
    "\n",
    "def generate_response(obs, guesses):\n",
    "    game_text = formatter.format_obs(obs, guesses)\n",
    "    game_text_len = len(game_text)\n",
    "    game_tokens = tokenize(game_text, tokenizer)\n",
    "    output_tokens = model.generate(input_ids=game_tokens[\"input_ids\"].to(\"cuda\"),\n",
    "                                   attention_mask=game_tokens[\"attention_mask\"].to(\"cuda\"),\n",
    "                                   pad_token_id = 2,\n",
    "                                   max_new_tokens=64)\n",
    "    output = tokenizer.batch_decode(output_tokens.detach().cpu().numpy(), skip_special_tokens=False)[0]  \n",
    "    output = formatter.format_response(output, game_text_len, obs) \n",
    "    if obs.turnType == 'guess':\n",
    "        guesses.append(output)\n",
    "    return output\n",
    "\n",
    "def generate_summary(obs):\n",
    "    game_text = formatter.summarizer_format(obs)\n",
    "    game_text_len = len(game_text)\n",
    "    game_tokens = tokenize(game_text, tokenizer)\n",
    "    output_tokens = model.generate(input_ids=game_tokens[\"input_ids\"].to(\"cuda\"),\n",
    "                                   attention_mask=game_tokens[\"attention_mask\"].to(\"cuda\"),\n",
    "                                   pad_token_id = 2,\n",
    "                                   max_new_tokens=256)\n",
    "    output = tokenizer.batch_decode(output_tokens.detach().cpu().numpy(), skip_special_tokens=False)[0]  \n",
    "    output = formatter.format_response(output, game_text_len, obs) \n",
    "    return output\n",
    "\n",
    "#################\n",
    "# Function to be called by the game environment\n",
    "\n",
    "def agent_fn(obs, cfg, guesses):\n",
    "    response = generate_response(obs, guesses)\n",
    "    #Catch glitched responses\n",
    "    if (response is None) or (len(response) <= 1) or (len(response) >= 200):\n",
    "        return \"yes\"    \n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ba898",
   "metadata": {
    "papermill": {
     "duration": 0.004888,
     "end_time": "2024-08-08T19:55:53.000987",
     "exception": false,
     "start_time": "2024-08-08T19:55:52.996099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Choose an example game by modifying the cell below. Turn types are 'ask', 'guess' and 'answer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d04b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:55:53.012588Z",
     "iopub.status.busy": "2024-08-08T19:55:53.012209Z",
     "iopub.status.idle": "2024-08-08T19:55:53.017996Z",
     "shell.execute_reply": "2024-08-08T19:55:53.017111Z"
    },
    "papermill": {
     "duration": 0.013983,
     "end_time": "2024-08-08T19:55:53.020121",
     "exception": false,
     "start_time": "2024-08-08T19:55:53.006138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_game = obs(\n",
    "    turnType = 'guess',\n",
    "    keyword = 'klein bottle',\n",
    "    category = 'thing',\n",
    "    questions = ['Is it a place?', \n",
    "                 'Is it broadly related to food, drinks or cooking?',\n",
    "                 'Is it broadly related to electronics or technology?',\n",
    "                 'Is it broadly related to arts, sports or entertainment?',\n",
    "                 'Is it broadly related to clothing, beauty or accessories?',\n",
    "                 'Is it man-made?',\n",
    "                 'Is it found indoors?',\n",
    "                 'Is it broadly related to furniture or architecture?'\n",
    "                ],\n",
    "    answers = ['no', 'no', 'no', 'no','no','yes','yes','yes']\n",
    ")\n",
    "\n",
    "test_guesses = ['chair', 'book', 'pen', 'clock', 'table', 'lamp', 'sofa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6d904d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:55:53.031422Z",
     "iopub.status.busy": "2024-08-08T19:55:53.031137Z",
     "iopub.status.idle": "2024-08-08T19:56:04.531166Z",
     "shell.execute_reply": "2024-08-08T19:56:04.530093Z"
    },
    "papermill": {
     "duration": 11.50799,
     "end_time": "2024-08-08T19:56:04.533193",
     "exception": false,
     "start_time": "2024-08-08T19:55:53.025203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is it a place?\n",
      "Answer:no\n",
      "Question: Is it broadly related to food, drinks or cooking?\n",
      "Answer:no\n",
      "Question: Is it broadly related to electronics or technology?\n",
      "Answer:no\n",
      "Question: Is it broadly related to arts, sports or entertainment?\n",
      "Answer:no\n",
      "Question: Is it broadly related to clothing, beauty or accessories?\n",
      "Answer:no\n",
      "Question: Is it man-made?\n",
      "Answer:yes\n",
      "Question: Is it found indoors?\n",
      "Answer:yes\n",
      "Question: Is it broadly related to furniture or architecture?\n",
      "Answer:yes\n",
      "\n",
      "\n",
      "Summary: The keyword is a type of furniture. It is primarily used for sitting or lying down. It is typically found in a living room or bedroom. It is a piece of furniture that is commonly found in households.\n"
     ]
    }
   ],
   "source": [
    "summary = generate_summary(test_game)\n",
    "print(f\"\\nSummary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbf16ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:56:04.545436Z",
     "iopub.status.busy": "2024-08-08T19:56:04.545123Z",
     "iopub.status.idle": "2024-08-08T19:56:04.549790Z",
     "shell.execute_reply": "2024-08-08T19:56:04.548985Z"
    },
    "papermill": {
     "duration": 0.013163,
     "end_time": "2024-08-08T19:56:04.551873",
     "exception": false,
     "start_time": "2024-08-08T19:56:04.538710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keyword is a type of furniture. It is primarily used for sitting or lying down. It is typically found in a living room or bedroom. It is a piece of furniture that is commonly found in households.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea531b9",
   "metadata": {
    "papermill": {
     "duration": 0.005003,
     "end_time": "2024-08-08T19:56:04.562344",
     "exception": false,
     "start_time": "2024-08-08T19:56:04.557341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run this cell to generate a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc6523a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:56:04.573863Z",
     "iopub.status.busy": "2024-08-08T19:56:04.573562Z",
     "iopub.status.idle": "2024-08-08T19:56:09.513950Z",
     "shell.execute_reply": "2024-08-08T19:56:09.512721Z"
    },
    "papermill": {
     "duration": 4.948737,
     "end_time": "2024-08-08T19:56:09.516199",
     "exception": false,
     "start_time": "2024-08-08T19:56:04.567462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Input -----\n",
      "[INST]You are an AI assistant playing the 20 Questions game. In this game the Answerer is given a secret keyword. The Questioner then asks yes-or-no questions regarding the keyword, and the Answerer answers them accurately. Then the Guesser tries to guess the keyword based on the questions and answers in the game.\n",
      "You are playing this game as the Guesser. After each question and answer you will guess what the keyword is based on the knowledge you have gained from the questions and answers about the keyword. Do NOT give repeated guesses.\n",
      "\n",
      "Round 1:\n",
      "Question: Is it a place?\n",
      "Answer: no.\n",
      "Now guess the keyword.[/INST]chair</s>\n",
      "[INST]Round 2: \n",
      "Question: Is it broadly related to food, drinks or cooking?\n",
      "Answer: no.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]book</s>\n",
      "[INST]Round 3: \n",
      "Question: Is it broadly related to electronics or technology?\n",
      "Answer: no.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]pen</s>\n",
      "[INST]Round 4: \n",
      "Question: Is it broadly related to arts, sports or entertainment?\n",
      "Answer: no.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]clock</s>\n",
      "[INST]Round 5: \n",
      "Question: Is it broadly related to clothing, beauty or accessories?\n",
      "Answer: no.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]table</s>\n",
      "[INST]Round 6: \n",
      "Question: Is it man-made?\n",
      "Answer: yes.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]lamp</s>\n",
      "[INST]Round 7: \n",
      "Question: Is it found indoors?\n",
      "Answer: yes.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]sofa</s>\n",
      "[INST]Round 8: \n",
      "Question: Is it broadly related to furniture or architecture?\n",
      "Answer: yes.\n",
      "Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\n",
      "Guess:[/INST]window</s>\n",
      "\n",
      "----- Model Response -----\n",
      "window\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(test_game, test_guesses)\n",
    "formatter_print = MistralPromptFormatter(inference_mode = False)\n",
    "\n",
    "print(\"----- Input -----\")\n",
    "print(formatter_print.format_obs(test_game, test_guesses))\n",
    "print(\"\\n----- Model Response -----\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5982e36b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:56:09.529619Z",
     "iopub.status.busy": "2024-08-08T19:56:09.529341Z",
     "iopub.status.idle": "2024-08-08T19:56:09.536484Z",
     "shell.execute_reply": "2024-08-08T19:56:09.535479Z"
    },
    "papermill": {
     "duration": 0.015644,
     "end_time": "2024-08-08T19:56:09.538492",
     "exception": false,
     "start_time": "2024-08-08T19:56:09.522848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_game(keyword):\n",
    "    curr_guesses = []\n",
    "    curr_game = obs(keyword = keyword, questions = [], answers = [], turnType = 'ask', category = None)\n",
    "    for turn in range(20):\n",
    "        curr_game.turnType = 'ask'\n",
    "        question = agent_fn(curr_game, None, curr_guesses)\n",
    "        print(f\"Question {turn+1}: {question}\")\n",
    "        curr_game.questions.append(question)\n",
    "        \n",
    "        curr_game.turnType = 'answer'\n",
    "        answer = agent_fn(curr_game, None, curr_guesses)\n",
    "        print(f\"Answer {turn+1}: {answer}\")\n",
    "        curr_game.answers.append(answer)\n",
    "        \n",
    "        curr_game.turnType = 'guess'\n",
    "        guess = agent_fn(curr_game, None, curr_guesses)\n",
    "        print(f\"Guess {turn+1}: {guess}\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7962608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T19:56:09.552038Z",
     "iopub.status.busy": "2024-08-08T19:56:09.551476Z",
     "iopub.status.idle": "2024-08-08T20:02:37.437007Z",
     "shell.execute_reply": "2024-08-08T20:02:37.435810Z"
    },
    "papermill": {
     "duration": 387.894419,
     "end_time": "2024-08-08T20:02:37.439156",
     "exception": false,
     "start_time": "2024-08-08T19:56:09.544737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Is it related to food, beverages or cooking?\n",
      "Answer 1: no\n",
      "Guess 1: Car\n",
      "\n",
      "Question 2: Is it related to industrial production or manufacturing?\n",
      "Answer 2: no\n",
      "Guess 2: Tree\n",
      "\n",
      "Question 3: Is it broadly related to entertainment or sports?\n",
      "Answer 3: yes\n",
      "Guess 3: Television\n",
      "\n",
      "Question 4: Is it something a person can hold in their hand?\n",
      "Answer 4: yes\n",
      "Guess 4: Playing card\n",
      "\n",
      "Question 5: Is it related to electronics or technology?\n",
      "Answer 5: no\n",
      "Guess 5: Book\n",
      "\n",
      "Question 6: Is it broadly related to the arts or media?\n",
      "Answer 6: no\n",
      "Guess 6: Board game\n",
      "\n",
      "Question 7: Is it used in a specific sport or recreational activity?\n",
      "Answer 7: yes\n",
      "Guess 7: Tennis ball\n",
      "\n",
      "Question 8: Is it used in a team sport?\n",
      "Answer 8: yes\n",
      "Guess 8: Soccer ball\n",
      "\n",
      "Question 9: Is it a type of ball?\n",
      "Answer 9: no\n",
      "Guess 9: Hockey stick\n",
      "\n",
      "Question 10: Is it protective equipment?\n",
      "Answer 10: no\n",
      "Guess 10: Whistle\n",
      "\n",
      "Question 11: Is it used to score points or goals in a game?\n",
      "Answer 11: no\n",
      "Guess 11: Referee flag\n",
      "\n",
      "Question 12: Is it a type of jersey or clothing?\n",
      "Answer 12: no\n",
      "Guess 12: Football\n",
      "\n",
      "Question 13: Is it equipment used to keep track of time during a game?\n",
      "Answer 13: no\n",
      "Guess 13: Scoreboard\n",
      "\n",
      "Question 14: Is it a type of award or trophy given in a sport?\n",
      "Answer 14: yes\n",
      "Guess 14: Golden Globe\n",
      "\n",
      "Question 15: Is it the Nobel Peace Prize?\n",
      "Answer 15: no\n",
      "Guess 15: Oscar\n",
      "\n",
      "Question 16: Is it the FIFA World Cup trophy?\n",
      "Answer 16: no\n",
      "Guess 16: Emmy\n",
      "\n",
      "Question 17: Is it the Olympic gold medal?\n",
      "Answer 17: no\n",
      "Guess 17: Stanley Cup\n",
      "\n",
      "Question 18: Is it the Stanley Cup?\n",
      "Answer 18: no\n",
      "Guess 18: Heisman Trophy\n",
      "\n",
      "Question 19: Is it the Super Bowl trophy?\n",
      "Answer 19: no\n",
      "Guess 19: World Series Trophy\n",
      "\n",
      "Question 20: Is it the World Series trophy?\n",
      "Answer 20: no\n",
      "Guess 20: NBA Championship Ring\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulate_game('trophy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5071d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T20:02:37.460981Z",
     "iopub.status.busy": "2024-08-08T20:02:37.460412Z",
     "iopub.status.idle": "2024-08-08T20:02:38.123308Z",
     "shell.execute_reply": "2024-08-08T20:02:38.122168Z"
    },
    "papermill": {
     "duration": 0.675872,
     "end_time": "2024-08-08T20:02:38.125303",
     "exception": false,
     "start_time": "2024-08-08T20:02:37.449431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pygame installed, ignoring import\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make\n",
    "import kaggle_environments\n",
    "import random\n",
    "\n",
    "def random_agent(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = \"Is it a duck?\"\n",
    "    elif obs.turnType == \"guess\": response = \"duck\"\n",
    "    elif obs.turnType == \"answer\": \n",
    "        random_int = random.randint(0, 1)\n",
    "        if random_int: response = \"Yes\"\n",
    "        else: response = \"No\"\n",
    "    return response\n",
    "\n",
    "class obs(object):\n",
    "    def __init__(self, turnType, keyword, category, questions, answers):\n",
    "        self.turnType = turnType\n",
    "        self.keyword = keyword\n",
    "        self.category = category\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        \n",
    "keyword = \"argentina\"\n",
    "alts = [\"argentina\"]\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.category = \"Place\"\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword_obj = {'keyword':keyword,'alts':alts}\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword = keyword\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.alts = alts\n",
    "\n",
    "#env = make(\"llm_20_questions\", debug=True)\n",
    "#game_output = env.run(agents=[agent_fn, random_agent, random_agent, random_agent])\n",
    "#env.render(mode=\"ipython\", width=800, height=400)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "modelId": 93827,
     "modelInstanceId": 68660,
     "sourceId": 81709,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 95155,
     "modelInstanceId": 70048,
     "sourceId": 83386,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 96205,
     "modelInstanceId": 71206,
     "sourceId": 84765,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 91014,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 592.432143,
   "end_time": "2024-08-08T20:02:41.269221",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-08T19:52:48.837078",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "081abe6c20284e58b3035d535adb03b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c8db45967c84cafa75366638c67a91b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18bffb43845543349d85fe8ba24ae031": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "22ca58fde4304e678ad76dd2040f4a67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "634cb031d3d647518caff21eed5d0025": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_beb304105fd24d599d287b32a426b901",
        "IPY_MODEL_98d50699f2c142c0a2941170ede93498",
        "IPY_MODEL_ea42d3dc4b774f8fb794d5bbbf73060d"
       ],
       "layout": "IPY_MODEL_081abe6c20284e58b3035d535adb03b5"
      }
     },
     "7123b6b54ffe437cb45673a61c62adc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "98d50699f2c142c0a2941170ede93498": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_22ca58fde4304e678ad76dd2040f4a67",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_18bffb43845543349d85fe8ba24ae031",
       "value": 2.0
      }
     },
     "beb304105fd24d599d287b32a426b901": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c8db45967c84cafa75366638c67a91b",
       "placeholder": "​",
       "style": "IPY_MODEL_7123b6b54ffe437cb45673a61c62adc9",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "ea42d3dc4b774f8fb794d5bbbf73060d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc7ce0a4d3314c708a4664132cf67d51",
       "placeholder": "​",
       "style": "IPY_MODEL_fb39b28d1c204e9ba4694763a80a62bf",
       "value": " 2/2 [01:40&lt;00:00, 48.25s/it]"
      }
     },
     "fb39b28d1c204e9ba4694763a80a62bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fc7ce0a4d3314c708a4664132cf67d51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
