{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5c39cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:48:03.389107Z",
     "iopub.status.busy": "2024-08-13T22:48:03.388382Z",
     "iopub.status.idle": "2024-08-13T22:50:14.993532Z",
     "shell.execute_reply": "2024-08-13T22:50:14.992492Z"
    },
    "papermill": {
     "duration": 131.613104,
     "end_time": "2024-08-13T22:50:14.995822",
     "exception": false,
     "start_time": "2024-08-13T22:48:03.382718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.43.3\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers==4.43.3)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.43.3)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.43.3)\n",
      "  Downloading numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=20.0 (from transformers==4.43.3)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.43.3)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.43.3)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from transformers==4.43.3)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.43.3)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.43.3)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.43.3)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.43.3)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.43.3)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.43.3)\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.43.3)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hSaved /tmp/submission/transformers-4.43.3-py3-none-any.whl\n",
      "Saved /tmp/submission/huggingface_hub-0.24.5-py3-none-any.whl\n",
      "Saved /tmp/submission/numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/packaging-24.1-py3-none-any.whl\n",
      "Saved /tmp/submission/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/tqdm-4.66.5-py3-none-any.whl\n",
      "Saved /tmp/submission/filelock-3.15.4-py3-none-any.whl\n",
      "Saved /tmp/submission/requests-2.32.3-py3-none-any.whl\n",
      "Saved /tmp/submission/certifi-2024.7.4-py3-none-any.whl\n",
      "Saved /tmp/submission/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/fsspec-2024.6.1-py3-none-any.whl\n",
      "Saved /tmp/submission/idna-3.7-py3-none-any.whl\n",
      "Saved /tmp/submission/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Saved /tmp/submission/urllib3-2.2.2-py3-none-any.whl\n",
      "Successfully downloaded transformers huggingface-hub numpy packaging pyyaml regex safetensors tokenizers tqdm filelock requests certifi charset-normalizer fsspec idna typing-extensions urllib3\n",
      "Collecting bitsandbytes==0.43.2\n",
      "  Downloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting torch (from bitsandbytes==0.43.2)\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting numpy (from bitsandbytes==0.43.2)\n",
      "  File was already downloaded /tmp/submission/numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting filelock (from torch->bitsandbytes==0.43.2)\n",
      "  File was already downloaded /tmp/submission/filelock-3.15.4-py3-none-any.whl\n",
      "Collecting typing-extensions>=4.8.0 (from torch->bitsandbytes==0.43.2)\n",
      "  File was already downloaded /tmp/submission/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Collecting sympy (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch->bitsandbytes==0.43.2)\n",
      "  File was already downloaded /tmp/submission/fsspec-2024.6.1-py3-none-any.whl\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch->bitsandbytes==0.43.2)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.2)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->bitsandbytes==0.43.2)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch->bitsandbytes==0.43.2)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hSaved /tmp/submission/bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl\n",
      "Saved /tmp/submission/torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Saved /tmp/submission/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "Saved /tmp/submission/jinja2-3.1.4-py3-none-any.whl\n",
      "Saved /tmp/submission/networkx-3.3-py3-none-any.whl\n",
      "Saved /tmp/submission/sympy-1.13.2-py3-none-any.whl\n",
      "Saved /tmp/submission/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/mpmath-1.3.0-py3-none-any.whl\n",
      "Saved /tmp/submission/nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl\n",
      "Successfully downloaded bitsandbytes numpy torch nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nccl-cu12 nvidia-nvtx-cu12 triton typing-extensions filelock fsspec jinja2 networkx sympy MarkupSafe mpmath nvidia-nvjitlink-cu12\n",
      "Collecting accelerate==0.32.1\n",
      "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting numpy<2.0.0,>=1.17 (from accelerate==0.32.1)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m55.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=20.0 (from accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/packaging-24.1-py3-none-any.whl\n",
      "Collecting psutil (from accelerate==0.32.1)\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting pyyaml (from accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting torch>=1.10.0 (from accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Collecting huggingface-hub (from accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/huggingface_hub-0.24.5-py3-none-any.whl\n",
      "Collecting safetensors>=0.3.1 (from accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting filelock (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/filelock-3.15.4-py3-none-any.whl\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Collecting sympy (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/sympy-1.13.2-py3-none-any.whl\n",
      "Collecting networkx (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/networkx-3.3-py3-none-any.whl\n",
      "Collecting jinja2 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/jinja2-3.1.4-py3-none-any.whl\n",
      "Collecting fsspec (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/fsspec-2024.6.1-py3-none-any.whl\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting triton==3.0.0 (from torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl\n",
      "Collecting requests (from huggingface-hub->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/requests-2.32.3-py3-none-any.whl\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/tqdm-4.66.5-py3-none-any.whl\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/idna-3.7-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/urllib3-2.2.2-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/certifi-2024.7.4-py3-none-any.whl\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.10.0->accelerate==0.32.1)\n",
      "  File was already downloaded /tmp/submission/mpmath-1.3.0-py3-none-any.whl\n",
      "Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hSaved /tmp/submission/accelerate-0.32.1-py3-none-any.whl\n",
      "Saved /tmp/submission/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Saved /tmp/submission/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Successfully downloaded accelerate numpy packaging safetensors torch nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nccl-cu12 nvidia-nvtx-cu12 triton huggingface-hub pyyaml psutil fsspec tqdm typing-extensions filelock jinja2 networkx requests sympy certifi charset-normalizer idna MarkupSafe mpmath urllib3 nvidia-nvjitlink-cu12\n",
      "Collecting peft==0.12.0\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting packaging>=20.0 (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/packaging-24.1-py3-none-any.whl\n",
      "Collecting psutil (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting pyyaml (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting torch>=1.13.0 (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Collecting transformers (from peft==0.12.0)\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/tqdm-4.66.5-py3-none-any.whl\n",
      "Collecting accelerate>=0.21.0 (from peft==0.12.0)\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting safetensors (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting huggingface-hub>=0.17.0 (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/huggingface_hub-0.24.5-py3-none-any.whl\n",
      "Collecting numpy>=1.17 (from peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting filelock (from huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/filelock-3.15.4-py3-none-any.whl\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/fsspec-2024.6.1-py3-none-any.whl\n",
      "Collecting requests (from huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/requests-2.32.3-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Collecting sympy (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/sympy-1.13.2-py3-none-any.whl\n",
      "Collecting networkx (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/networkx-3.3-py3-none-any.whl\n",
      "Collecting jinja2 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/jinja2-3.1.4-py3-none-any.whl\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "Collecting triton==3.0.0 (from torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl\n",
      "Collecting regex!=2019.12.17 (from transformers->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/idna-3.7-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/urllib3-2.2.2-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.17.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/certifi-2024.7.4-py3-none-any.whl\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.13.0->peft==0.12.0)\n",
      "  File was already downloaded /tmp/submission/mpmath-1.3.0-py3-none-any.whl\n",
      "Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hSaved /tmp/submission/peft-0.12.0-py3-none-any.whl\n",
      "Saved /tmp/submission/accelerate-0.33.0-py3-none-any.whl\n",
      "Saved /tmp/submission/transformers-4.44.0-py3-none-any.whl\n",
      "Successfully downloaded peft accelerate huggingface-hub numpy packaging pyyaml safetensors torch nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nccl-cu12 nvidia-nvtx-cu12 triton tqdm psutil transformers fsspec regex tokenizers typing-extensions filelock jinja2 networkx requests sympy certifi charset-normalizer idna MarkupSafe mpmath urllib3 nvidia-nvjitlink-cu12\n",
      "Collecting numpy==1.26.4\n",
      "  File was already downloaded /tmp/submission/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Successfully downloaded numpy\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tmp/submission\n",
    "\n",
    "import os, sys\n",
    "\n",
    "#os.system(\"pip install -U -t /kaggle/working/submission \\\"bitsandbytes==0.43.1\\\" accelerate \\\"peft==0.11.1\\\" \\\"numpy==1.26.4\\\"\")\n",
    "#os.system(\"pip install -U -t /kaggle/working/submission \\\"transformers==4.42.4\\\"\")\n",
    "os.system(\"pip download transformers==4.43.3 -d /tmp/submission\")\n",
    "os.system(\"pip download bitsandbytes==0.43.2 -d /tmp/submission\")\n",
    "os.system(\"pip download accelerate==0.32.1 -d /tmp/submission\")\n",
    "os.system(\"pip download peft==0.12.0 -d /tmp/submission\")\n",
    "os.system(\"pip download numpy==1.26.4 -d /tmp/submission\")\n",
    "\n",
    "#os.system(\"pip cache purge\")\n",
    "#os.system(\"cp -a /kaggle/working/submission/transformers /kaggle/working/submission/transformersnew\")\n",
    "sys.path.insert(0, \"/tmp/submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5a54b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:50:15.058361Z",
     "iopub.status.busy": "2024-08-13T22:50:15.057587Z",
     "iopub.status.idle": "2024-08-13T22:51:17.774246Z",
     "shell.execute_reply": "2024-08-13T22:51:17.772934Z"
    },
    "papermill": {
     "duration": 62.749574,
     "end_time": "2024-08-13T22:51:17.776820",
     "exception": false,
     "start_time": "2024-08-13T22:50:15.027246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/mistral-nemo-12b-4-bit/transformers/instruction-tuned/1/Mistral-Nemo-Instruct-12b-4bit /tmp/submission\n",
    "!cp -r /kaggle/input/20q-mistral-nemo-lora-adapters/transformers/default/8/FINAL_weights_for_real /tmp/submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5744298b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-13T22:51:17.837386Z",
     "iopub.status.busy": "2024-08-13T22:51:17.837025Z",
     "iopub.status.idle": "2024-08-13T22:51:17.845298Z",
     "shell.execute_reply": "2024-08-13T22:51:17.844466Z"
    },
    "papermill": {
     "duration": 0.040734,
     "end_time": "2024-08-13T22:51:17.847310",
     "exception": false,
     "start_time": "2024-08-13T22:51:17.806576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/submission/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/submission/main.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "import glob\n",
    "import importlib.util\n",
    "import traceback\n",
    "import pickle\n",
    "import socket\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# Host and port configuration for the socket connection\n",
    "host = \"127.0.0.1\"\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if not os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    KAGGLE_AGENT_PATH = \"/tmp/submission/\"\n",
    "    os.environ['PYTHONPATH'] = f\"{KAGGLE_AGENT_PATH}:{os.environ.get('PYTHONPATH', '')}\"\n",
    "sys.path.insert(0, KAGGLE_AGENT_PATH)\n",
    "\n",
    "def install_transformers():\n",
    "    install_command = [\n",
    "        sys.executable, '-m', 'pip', 'install',\n",
    "        '--no-index', '--upgrade', '--force-reinstall',\n",
    "        '--no-deps', f'--find-links={KAGGLE_AGENT_PATH}',\n",
    "        'transformers==4.43.3', 'bitsandbytes==0.43.2', 'accelerate==0.32.1', 'peft==0.12.0', 'huggingface_hub'\n",
    "    ]\n",
    "    subprocess.run(install_command, check=True)\n",
    "\n",
    "install_transformers()\n",
    "\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "def is_port_in_use(port):\n",
    "    \"\"\" Check if the given port is in use \"\"\"\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        return s.connect_ex(('127.0.0.1', port)) == 0\n",
    "\n",
    "def terminate_existing_servers(port):\n",
    "    \"\"\" Terminate any processes that are using the given port \"\"\"\n",
    "    for proc in psutil.process_iter(['pid', 'name']):\n",
    "        try:\n",
    "            for conns in proc.connections(kind='inet'):\n",
    "                if conns.laddr.port == port:\n",
    "                    proc.kill()\n",
    "        except psutil.AccessDenied:\n",
    "            continue\n",
    "\n",
    "# Find a free port\n",
    "port = find_free_port()\n",
    "\n",
    "# Ensure there are no existing servers using port\n",
    "terminate_existing_servers(port)\n",
    "\n",
    "# Start the background process\n",
    "process = subprocess.Popen([sys.executable, KAGGLE_AGENT_PATH + \"main2.py\", str(port)])\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    data = pickle.dumps((obs, cfg))\n",
    "    \n",
    "    # Retry configuration\n",
    "    retries = 10\n",
    "    delay = 6  # seconds\n",
    "    while retries:\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                time.sleep(1)\n",
    "                s.connect(('127.0.0.1', port))\n",
    "                s.sendall(data)\n",
    "                result_data = s.recv(4096)\n",
    "                result = pickle.loads(result_data)\n",
    "                return result\n",
    "        except ConnectionRefusedError:\n",
    "            print(f\"Connection refused, retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "            retries -= 1\n",
    "        except ConnectionResetError:\n",
    "            print(f\"Connection reset by peer, returning 'yes'\")\n",
    "            return \"yes\"\n",
    "    \n",
    "    raise ConnectionError(\"Failed to connect to the server after multiple attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e20a946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:51:17.913052Z",
     "iopub.status.busy": "2024-08-13T22:51:17.912713Z",
     "iopub.status.idle": "2024-08-13T22:51:17.941882Z",
     "shell.execute_reply": "2024-08-13T22:51:17.940967Z"
    },
    "papermill": {
     "duration": 0.066109,
     "end_time": "2024-08-13T22:51:17.943777",
     "exception": false,
     "start_time": "2024-08-13T22:51:17.877668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/submission/main2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/submission/main2.py\n",
    "\n",
    "import pickle\n",
    "import socket\n",
    "\n",
    "\n",
    "################\n",
    "# Determine if submit or commit and import necessary packages\n",
    "\n",
    "import os, sys\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "VERBOSE = False\n",
    "os.environ['PYTHONPATH'] = \"/tmp/submission:\" + os.environ.get('PYTHONPATH', '')\n",
    "if not os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    KAGGLE_AGENT_PATH = \"/tmp/submission/\"\n",
    "    VERBOSE = True\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    PreTrainedTokenizerBase\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "sys.path.insert(0, KAGGLE_AGENT_PATH)   \n",
    "\n",
    "\n",
    "#################\n",
    "# Configure and load model into memory\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "host = \"127.0.0.1\"  # Localhost\n",
    "port = int(sys.argv[1])  # Port passed as an argument\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name = f\"{KAGGLE_AGENT_PATH}Mistral-Nemo-Instruct-12b-4bit\"\n",
    "    lora_dir =  f\"{KAGGLE_AGENT_PATH}FINAL_weights_for_real\"\n",
    "    max_length = 1024\n",
    "    batch_size = 1\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False  \n",
    "    spread_max_length = False  \n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "#Load Mistral NeMo\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, add_bos_token = True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quanty_type = \"fp4\", \n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quanty = True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    torch_dtype = torch.float16,\n",
    "    device_map = \"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    "    trust_remote_code = True,\n",
    "    use_cache = False\n",
    ")\n",
    "\n",
    "\n",
    "#Add LoRA Adapters\n",
    "model = PeftModel.from_pretrained(model, cfg.lora_dir)\n",
    "\n",
    "\n",
    "#################\n",
    "# Prompts and tools for processing the game state\n",
    "\n",
    "import random\n",
    "\n",
    "list_prev_words = ['acacia', 'accent chair', 'acorn', 'adhd medication', 'adjustable bench', 'Advertisement', 'aerator', 'Agave', 'agave plant', 'Air compressor', 'Air Conditioner', 'Air filter', 'air handler', 'air plant', 'air tank', 'Air vent', 'airport lighting', 'Alarm system', 'alfalfa', 'almond milk', 'aluminum foil', 'amazon echo', 'analog stick', 'Analogy', 'anchovy', 'Anemone', 'Anesthesia', 'angelfish', 'ankle bracelet', 'antidepressant', 'antiseptic wipe', 'aperol spritz', 'apple', 'Apple pie', 'applesauce', 'apricot tree', 'Aprons', 'aquarium salt', 'archery target', 'arrival board', 'aspirin', 'Atmosphere', 'attic ladder', 'audio guide', 'autograph', 'automatic door', 'backgammon board', 'Backrest', 'bacon', 'Bacteria', 'baggage conveyor', 'Baguette', 'balance beam', 'bald eagle', 'ballpoint pen', 'bamboo', 'bamboo leaf', 'banana', 'bandana', 'bank statement', 'bar towel', 'barbell collar', 'Barber Chair', 'barcode', 'Bat', 'Bath Mat', 'battery', 'battery bank', 'beach chair', 'beach umbrella', 'bean', 'bean plant', 'Beanbag', 'bear', 'Bed frame', 'bedspread', 'beech tree', 'beer coaster', 'beer glass', 'beer stein', 'beer tap', 'Bike', 'binder clip', 'Binoculars', 'bird netting', 'Bird seed', 'Blinds', 'boa constrictor', 'Board Games', 'Bobby Pins', 'Bollards', 'Bonding Agent', 'bonsai tree', 'book cover', 'bookbag', 'Bookcase', 'bookend', 'Bookends', 'Bottled Water', 'bowl', 'bracelet', 'Bread knife', 'bread maker', 'Bread pudding', 'Brewery merchandise', 'Briefcase', 'Brochure', 'brochure stand', 'broken glass', 'broth', 'Brownies', 'brush', 'brussel sprout', 'buckle', 'Bug spray', 'Bulb', 'bulletin', 'bumble bee', 'bumper', 'Bumper sticker', 'bunk bed', 'Bunsen burner', 'butter', 'butter knife', 'butterfly', 'butterfly net', 'button', 'cable tie', 'cable tray', 'cactus flower', 'cake', 'calcite', 'calculator', 'camp stove', 'candle holder', 'candy wrapper', 'cane', 'canning jar', 'cannoli', 'Cantaloupe', 'car antenna', 'car engine', 'car seat', 'carbon', 'Card', 'cardboard', 'Cardboard box', 'cardboard tube', 'caribou', 'carnation', 'Cash Register', 'casket', 'Cat carrier', 'catalytic converter', 'catheter', 'Cauliflower', 'cedar', 'Ceiling fan', 'centerpiece', 'centipede', 'Cereal', 'cereal bar', 'chair cushion', 'Champagne flute', 'Chandelier', 'charger', 'charging cord', 'Cheesecake', 'cherry tree', 'Chessboard', 'Chew toy', 'chicken wire', 'chiller', 'chime', 'chimney', 'chimpanzee', 'chocolate bar', 'Chocolate cake', 'cholla cactus', 'christmas tree', 'chutney', 'cilantro', 'cinder block', 'Cinnamon roll', 'clay', 'climber', 'climbing rope', 'clip', 'clock', 'clog', 'clothes rack', 'clutch bag', 'coal crusher', 'Coat Rack', 'cobblestone', 'cobweb', 'cockroach', 'cocktail glass', 'coconut', 'coffee bag', 'Coffee beans', 'Coffee Grinder', 'coffee ground', 'Coffee grounds', 'coffee machine', 'Coffee Makers', 'coffee mug', 'coffee table', 'coffin', 'coke', 'colander', 'cold pack', 'Comic Book', 'common milkweed', 'compactor', 'compass', 'compost', 'concentrator', 'concrete block', 'concrete wall', 'condenser', 'conditioner', 'conference table', 'Contact lenses', 'Conveyor belt', 'cooler', 'Cooling Tower', 'cordless phone', 'corkscrew', 'cotton', 'cotton candy', 'cowboy boot', 'crayfish', 'Cream cheese', 'crochet hook', 'Croissant', 'cruise ship', 'crutch', 'cuff', 'culture medium', 'cupcake', 'curler', 'curling', 'curling iron', 'Curtains', 'cuticle', 'Cutlery', 'cutter', 'Cutting Board', 'cypress knee', 'daisy', 'damselfish', 'Dandelion', 'dashboard camera', 'dead leaf', 'decal', 'Deciduous tree', 'denim', 'denim jeans', 'dental chair', 'deposit slip', 'Desk Chairs', 'desk lamp', 'desktop computer', 'Diaper', 'diary', 'dill pickle', 'dining chair', 'dinosaur skeleton', 'Dish soap', 'dishcloth', 'dishtowel', 'dishwasher', 'Disinfectant', 'Diving board', 'dj mixer', 'dj turntable', 'docket', 'dog poop', 'Dog shampoo', 'dog tag', 'dogwood', 'dolphin', 'domino', 'Donuts', 'door', 'doughnut', 'Drain Hose', 'drainage pipe', 'drapery', 'Drapes', 'dresser', 'drill bit', 'drying rack', 'duckweed', 'ducky', 'duct', 'Duct tape', 'Duffle Bags', 'Dumbbells', 'Dump truck', 'dust jacket', 'Duvet', 'duvet cover', 'DVD', 'DVD Player', 'dye', 'Dynamite', 'ear drop', 'Ear protection', 'Earl Grey tea', 'earplug', 'earring', 'earthworm', 'Edamame', 'Edible flowers', 'elastic bandage', 'elbow pad', 'electric bike', 'electric fan', 'electric motorcycle', 'electric oven', 'electric razor', 'electric saw', 'electric scooter', 'electric screwdriver', 'electric toothbrush', 'electric violin', 'Electrical panel', 'electrical tape', 'electronic keyboard', 'electronic piano', 'Elevator', 'Elliptical Trainers', 'embroidery', 'Emergency Exit Sign', 'emergency light', 'emergency lighting', 'Emergency lights', 'empty can', 'enamel', 'enamel pin', 'end table', 'Energy drink', 'engagement ring', 'engine oil', 'Engravings', 'entrance door', 'envelope', 'eruption', 'Escalators', 'espresso machine', 'Eucalyptus', 'evaporator', 'excavator', 'exercise mat', 'Exhaust Fan', 'exhibit sign', 'Exit sign', 'Extension Cord', 'extension ladder', 'eye', 'eye mask', 'eyeglass', 'fabric roll', 'fabric sofa', 'Face mask', 'Facial Toner', 'fallen log', 'fallen tree', 'fan blade', 'Fanny pack', 'fanta', 'feather boa', 'fence gate', 'fence panel', 'fennel', 'fern', 'Fertilizer', 'file folder', 'finger', 'Finger food', 'fir', 'Fire alarm', 'fire coral', 'Fire Escape Ladder', 'Fire Extinguisher', 'fire helmet', 'fire hydrant', 'fireplace mantle', 'First Aid Kit', 'fish scale', 'fishing net', 'fishing rod', 'fishnet', 'Fitness tracker', 'flashlight', 'flat shoe', 'flea', 'Floor jacks', 'Floor Mats', 'flour', 'flower crown', 'foam roller', 'Fog machine', 'foil paper', 'Food bowl', 'Food warmers', 'footbridge', 'footrest', 'Fortune cookie', 'fossil', 'fox', 'frappe', 'Frappuccino', 'Free Weights', 'French toast', 'fresheners', 'Fridge magnet', 'Fried rice', 'frisbee', 'frozen meat', 'frozen waffle', 'fruit cup', 'fudge brownie', 'fuel filter', 'Fungi', 'fur', 'Furniture', 'Furniture polish', 'Fuse', 'Gadget', 'game board', 'Garbage bag', 'Garbage Disposal', 'garbage truck', 'garden fork', 'garden rake', 'garden shovel', 'garment rack', 'garment steamer', 'garter', 'gas cap', 'Gas Mask', 'gas stove', 'gas turbine', 'gasket', 'gator', 'gecko', 'gel', 'gelatin', 'Generator', 'ghost crab', 'gift bag', 'gift box', 'gin', 'ginger', 'ginger ale', 'giraffe', 'glass figurine', 'glass panel', 'glass sheet', 'glass shelf', 'Glass Table', 'glass window', 'glitter', 'Glove', 'gold', 'Golf Cart', 'goose', 'gown', 'GPS', 'graduated cylinder', 'granola', 'grape', 'grape juice', 'Grape Vine', 'Grapefruit', 'Graphic Novel', 'Graphing Calculator', 'Gravity', 'green alga', 'Green beans', 'Greeting Card', 'grill', 'grinder', 'groundhog', 'guitar pick', 'Guitar String', 'guppy', 'gutter', 'Gym Mats', 'Habanero pepper', 'hacksaw', 'Hair clip', 'hair clipper', 'Hair Dryer', 'hair elastic', 'Hair Gel', 'hair tie', 'Hairbrush', 'Hairspray', 'hairspray can', 'ham', 'hamburger helper', 'hamster', 'Hamster wheel', 'Hamstring Curl Machine', 'hand drill', 'Hand dryer', 'hand lotion', 'hand pruner', 'Hand Sanitizer', 'Handbag', 'handcuff', 'handlebar', 'Handrail', 'hanging basket', 'hanging hook', 'Hard hat', 'Hash browns', 'hat', 'hay bale', 'Hazelnut', 'hazelnut tree', 'HDMI cable', 'headband', 'headboard', 'Headlamp', 'headlight', 'headphone', 'Headphones', 'Hearing aid', 'Heart Rate Monitors', 'Heating Element', 'Hibiscus', 'High Chair', 'highlighter', 'Hiking boots', 'hole puncher', 'honey', 'Honeybee', 'honeycrisp', 'honeydew', 'honeydew melon', 'hose line', 'hospital bed', 'Hot dog', 'hot tea', 'Hot water bottle', 'house key', 'humidity meter', 'hummus', 'humus', 'hvac system', 'hydrant', 'hydro turbine', 'Ice cream maker', 'ice crusher', 'Ice cube tray', 'ice pop', 'ice sculpture', 'ice tea', 'ice tray', 'Ice Water', 'Iced coffee', 'Icicle', 'igloo', 'ignition system', 'impact crusher', 'impact wrench', 'impatiens', 'Incense', 'Index Card', 'infrared sensor', 'Inhaler', 'ink cartridge', 'Insulation', 'internet modem', 'internet router', 'Interstate', 'inverter', 'invoice', 'iris', 'Iron', 'Iron bar', 'Ironing Board', 'Irrigation system', 'IV', 'iv bag', 'jack stand', 'jacket', 'jaffa cake', 'jam', 'jane', 'jasmine', 'jello', 'Jewelry Box', 'Journal', 'Joystick', 'juice box', 'juicer', 'Jumper Cables', 'junction box', 'juniper bush', 'juniper tree', 'Kale smoothie', 'Karaoke machine', 'kelp', 'ketchup', 'Key chain', 'key ring', 'keyring', 'Khaki pants', 'kheer', 'kickstand', 'king snake', 'Kitchen cabinet', 'kitchen knife', 'kiwifruit', 'knapweed', 'knitting needle', 'Komodo dragon', 'Lab coat', 'laboratory manual', 'lace', 'lace dress', 'lace top', 'Lanyard', 'Laptop', 'Laser beam', 'Lathe', 'Latte', 'laundry basket', 'laundry cart', 'lawn mower', 'Lawnmower', 'laxative', 'leaf', 'leaf rake', 'leash', 'legal pad', 'Lego', 'lemming', 'lemon balm', 'lemon juice', 'lemon wedge', 'lemon zest', 'leopard', 'leotard', 'level sensor', 'Library Card', 'library stamp', 'license plate', 'lid', 'lifter', 'lifting belt', 'lifting crane', 'Light Switch', 'Lightbulb', 'lighting rig', 'lily', 'lime', 'limousine', 'linen', 'lint brush', 'Lint Roller', 'lint trap', 'lipstick', 'Litter scooper', 'livestock trailer', 'loose change', 'Lottery Ticket', 'lug', 'Luggage', 'magnet', 'mail truck', 'maintenance truck', 'mango', 'mango tree', 'mangrove seedling', 'manicure set', 'maple tree', 'Marshmallow', 'martini', 'Masks', 'Matches', 'maxi dress', 'Measuring cup', 'measuring spoon', 'Measuring Tape', 'meatloaf', 'medallion', 'medical cart', 'medical chart', 'medical gown', 'Medical Records', 'Medication', 'medication dispenser', 'melon', 'Menorah', 'merchandise rack', 'mesquite tree', 'Metal detector', 'metal file', 'metal foil', 'metal lid', 'metal spoon', 'mic stand', 'microphone stand', 'Microscope', 'Microwave', 'migraine', 'milkweed', 'milling', 'Milling machine', 'Mini fridge', 'miniskirt', 'Mixing Bowl', 'mixing console', 'Mobile phone', 'model airplane', 'Modem', 'moleskin', 'mop', 'mortar', 'moss ball', 'motion sensor', 'motor', 'motorcycle', 'Motorcycle Helmet', 'mount saint lias', 'Mouse', 'mousepad', 'Movie poster', 'moving walkway', 'mri', 'mri machine', 'mucus', 'Muffin', 'Muffin Tin', 'Muffler', 'Mural', 'muscle relaxant', 'Mushroom', 'Nachos', 'Nail clipper', 'Nail polish', 'Nail Polish Remover', 'Name tag', 'Nap mat', 'Necklace', 'needle', 'neon light', 'netgear', 'nightshade', 'nile monitor', 'nintendo switch', 'nitrogen', 'nitrous', 'noise-canceling headphones', 'nokia phone', 'noodle', 'northern cardinal', 'northern mockingbird', 'nose', 'nose ring', 'Notebook', 'Nozzle', 'nylon', 'Oak table', 'oak tree', 'oakley sunglasses', 'oar', 'oatmeal cookie', 'Ocarina', 'office chair', 'oil filter', 'Ointment', 'Olive Oil', 'Onyx', 'operating table', 'orange juice', 'Orange peel', 'orange slice', 'Orange tree', 'Orange zest', 'ostrich', 'ottoman', 'Outdoor Furniture', 'Oven door', 'Oven rack', 'overhead wire', 'owl', 'oxygen', 'Oxygen tank', 'oyster', 'Pacifier', 'Packing peanuts', 'Pad', 'pail', 'paint roller', 'paint sprayer', 'paint thinner', 'paintbrush', 'Pajamas', 'Pallet Jack', 'palmetto tree', 'Pamphlet', 'pant', 'Pants', 'paper roll', 'Paper towels', 'Paperweights', 'Paperwork', 'parachute', 'Parallel bars', 'park map', 'parking pass', 'parrot', 'parrotfish', 'parsley', 'parts cleaner', 'pea plant', 'pea soup', 'peace lily', 'peach tree', 'peanut butter', 'pear tree', 'pedal boat', 'peeler', 'pelican', 'pellet', 'Pencil Sharpener', 'penguin', 'peony', 'pepper spray', 'peppermint', 'Perfume', 'perfume bottle', 'Personal protective equipment', 'Pesticide', 'petroleum', 'petunia', 'phone case', 'Phone charger', 'Photo album', 'photocopier', 'piano', 'piano stool', 'Pickaxe', 'picket', 'picnic basket', 'picture frame', 'pilates', 'pilates reformer', 'pillow sham', 'pillowcase', 'pillowtop', 'pine cone', 'pineapple', 'pipe', 'pipette', 'Piping tips', 'piranha', 'pitcher', 'pizza box', 'Placemat', 'plant saucer', 'planter', 'Planter Box', 'Plaque', 'plastic baggie', 'plastic chair', 'plastic fork', 'Plastic Gloves', 'plastic pallet', 'plastic pipe', 'plastic sign', 'plastic tub', 'plastic tube', 'Plastic wrap', 'Plate', 'Play mat', 'Playing cards', 'Pliers', 'plunger', 'polar bear', 'Polyester', 'pomegranate', 'Pool cleaner', 'Popcorn', 'Popcorn machine', 'porcupine', 'Portable speaker', 'possum', 'postage stamp', 'pot holder', 'Potato', 'potato chip', 'potted plant', 'power adapter', 'power cable', 'power cord', 'Power Drill', 'power grid', 'Power lines', 'power meter', 'power pole', 'Power strip', 'prairie sunflower', 'Pressure gauge', 'projector', 'Protein bar', 'protein shake', 'Protein Shakes', 'Pry Bar', 'Public Address System', 'pudding', 'pumpkin', 'Pumpkin pie', 'punching bag', 'purse', 'push pin', 'Puzzle', 'Quesadilla', 'Rabbit', 'raccoon', 'Radio scanner', 'Radish', 'Rags', 'rail track', 'rainboot', 'rainbow cake', 'Raindrops', 'raisin', 'ramen', 'rangefinder', 'raspberry', 'Rat', 'reading glasses', 'reading pillow', 'receipt printer', 'Red velvet cake', 'Red wine', 'redwood tree', 'refrigerator', 'Reindeer', 'relief valve', 'Relish', 'Reptile', 'Resin', 'Respirator', 'rhubarb', 'ribbon', 'rice krispie', 'Rice pudding', 'ricotta', 'Rivet', 'roadrunner', 'Robot arm', 'rocketship', 'rocking chair', 'roller', 'rollercoaster', 'Rolling pin', 'rooster', 'Roots', 'rose', 'rose bush', 'rosemary', 'Router', 'Rowing machines', 'rubber', 'ruby', 'rucksack', 'Rug', 'ruler', 'rusty nail', 'RV', 'safety glasses', 'safety goggles', 'Safety harness', 'safety railing', 'Salad Dressing', 'salt scrub', 'salt shaker', 'saltwater', 'sandal', 'sandhill crane', 'sandstorm', 'sash', 'Satellite', 'satellite dish', 'saucer', 'sauerkraut', 'school bus', 'Scones', 'Scoreboard', 'Scrap metal', 'Scratching posts', 'screen', 'Screwdriver', 'scrubber', 'sea turtle', 'seafoam', 'seagrass', 'seagull', 'seahorse', 'sealant', 'sealing machine', 'seam', 'security gate', 'Security systems', 'sedge', 'Seed packet', 'seedling tray', 'seltzer', 'serving bowl', 'serving platter', 'sewage system', 'Sewing Kit', 'sewing needle', 'shaker', 'sheetrock', 'Shin Guards', 'shingle', 'shipping container', 'Shipping label', 'shirt', 'shoelace', 'shop towel', 'shovel', 'Shower caddy', 'shower cap', 'shower chair', 'shower mat', 'Sieve', 'silicon', 'Silicone', 'Silicone mat', 'Silver ore', 'Sippy cup', 'Sketchbook', 'skewer', 'Sleeping bag', 'sling', 'slit', 'smartboard', 'Smartphone', 'Smartwatch', 'smith machine', 'smoke alarm', 'Smoke Detector', 'smoothie', 'Snacks', 'snake', 'snowball', 'snowdrift', 'snowmobile', 'Soap Dispenser', 'Soap Suds', 'soccer ball', 'sock', 'Soda', 'sofa', 'solar panel', 'Soldering iron', 'sorting machine', 'Sound system', 'soundboard', 'soup', 'Soybeans', 'Space probe', 'spare bulb', 'Spatula', 'spider web', 'spirit level', 'Sportswear', 'Spotlight', 'spray', 'Sprinkler', 'Sprinkler System', 'squash', 'squid', 'Squirrel', 'Stage lights', 'Stain Remover', 'Stained glass window', 'Stair Stepper', 'staircase', 'stationary bike', 'steak', 'steak knife', 'steam iron', 'steel sheet', 'steering wheel', 'stick', 'Sticker', 'Sticky notes', 'Stove', 'straightening iron', 'strainer', 'Street sign', 'streetlamp', 'strobe light', 'stroller', 'stump', 'Sugar packet', 'Suitcase', 'sumantri', 'sunglass', 'sunglasses', 'Sunscreen', 'support beam', 'surgical drape', 'survey marker', 'sushi', 'suture', 'swamp milkweed', 'swedish fish', 'sweet tea', 'sweetgum tree', 'swimsuit', 'Swing set', 'sword fern', 'sycamore tree', 'syrup', 'Tablet', 'tackle box', 'Tank', 'tank top', 'tape dispenser', 'tape measure', 'Taser', 'tassel', 'tea bag', 'tea cup', 'tea leaf', 'teddy bear', 'telephone', 'Telescope', 'Television', 'television remote', 'Tennis ball', 'test strip', 'thermal underwear', 'thermometer probe', 'throw blanket', 'throw rug', 'thumbtack', 'thyroid', 'thyroid medication', 'Ticket Machine', 'Ticket stub', 'tile', 'tin foil', 'tiramisu', 'tire', 'tire gauge', 'tire inflator', 'tire iron', 'Tissue box', 'toad', 'Toaster Oven', 'Tofu', 'toilet brush', 'Toiletries bag', 'Tomato', 'tomato plant', 'tongue', 'Tongue Depressor', 'Tool Belt', 'Tool Box', 'Toothbrush', 'Toothpaste', 'toothpick', 'tote bin', 'Touchscreen', 'tow strap', 'Tow truck', 'Towel', 'towel basket', 'Tracksuit', 'Tractor', 'traffic signal', 'Train brake', 'Train door', 'train horn', 'training cone', 'transmission tower', 'Trash bag', 'travel pillow', 'trellis', 'trench coat', 'Tricycle', 'trimming scissors', 'trinket box', 'trophy', 'trouser', 'Truck', 'trumpet', 'Tulip', 'tuning fork', 'tupperware', 'Turn signal', 'Turnstiles', 'turtle', 'Tweezers', 'twine', 'Udon Noodles', 'ukulele case', 'ultrasound', 'Ultraviolet Lamp', 'Umbrella stand', 'unbuttoned jacket', 'underwater camera', 'underwater volcano', 'Unleavened Bread', 'unripe banana', 'unripe fruit', 'upholstered sofa', 'upright piano', 'Urinal', 'USB drives', 'usb stick', 'user manual', 'utility belt', 'Utility Box', 'Utility Cart', 'vacuum cleaner', 'valve', 'Vanilla Extract', 'Vanity mirror', 'Vans', 'varnish', 'Vase', 'vegan chocolate', 'Vegetable', 'vegetarian chili', 'Vegetation', 'Veggie Burger', 'velvet couch', 'velvet ribbon', 'Velvet rope', 'velvet rug', 'Vending Machine', 'ventilation fan', 'Ventilation System', 'vespa', 'vest', 'Video Camera', 'vietnamese coffee', 'vintage clock', 'vintage dollhouse', 'violin', 'violin bow', 'Violin Strings', 'Virus', 'voice recorder', 'volcanic ash', 'volkswagen', 'volleyball', 'vortex mixer', 'Voucher', 'VR Headset', 'walking stick', 'Wall Art', 'Wall Decorations', 'wall mirror', 'wall shelf', 'washcloth', 'Washing machine', 'wasp', 'wastewater', 'Water', 'Water Bottle', 'water bowl', 'Water Buffalo', 'water chestnut', 'water dish', 'Water Fountain', 'Water Heater', 'water hose', 'water hyacinth', 'water jug', 'water pump', 'water snake', 'water tank', 'water well', 'water wing', 'Watering Can', 'waterslide', 'wax', 'weasel', 'webcam', 'wedding ring', 'weighing scale', 'weight plate', 'weightlifting belt', 'Wheelchair ramp', 'whisk', 'Whistle', 'whiteboard', 'wig', 'wii', 'wild garlic', 'wind chime', 'wind vane', 'Windbreak', 'window cleaner', 'windsock', 'Wine Aerator', 'wine decanter', 'wine glass', 'Wine Opener', 'Wine Tasting Kit', 'wing', 'wiper', 'wire', 'wire brush', 'wire hanger', 'Wire rack', 'wireless microphone', 'Wireless Speaker', 'wisteria', 'wonton', 'wonton soup', 'wood chip', 'wooden spoon', 'woodpecker', 'woolen blanket', 'workout log', 'Wrench', 'Wrist Weights', 'Wristband', 'writing paper', 'yarrow', 'yeast', 'yoga block', 'Yoga mat', 'Yogurt', 'yogurt container', 'yule log', 'zinc', 'zip tie', 'ziploc']\n",
    "OLD_KEYWORDS = [word.lower() for word in list_prev_words]\n",
    "\n",
    "class MistralPromptFormatter:\n",
    "    def __init__(self, inference_mode = True):\n",
    "        self.sys_prompt = \"You are an AI assistant playing the 20 Questions game. In this game the Answerer is given a secret keyword. \"\\\n",
    "        \"The Questioner then asks yes-or-no questions regarding the keyword, and the Answerer answers them accurately. \"\\\n",
    "        \"Then the Guesser tries to guess the keyword based on the questions and answers in the game.\\n\"\n",
    "        self.inference_mode = inference_mode\n",
    "        \n",
    "    def format_instruction(self, instruction):\n",
    "        return f\"[INST]{instruction}[/INST]\"\n",
    "    \n",
    "    def format_obs(self, obs, guesses):\n",
    "        if obs.turnType == 'ask':\n",
    "            return self.ask_format(obs, guesses)\n",
    "        if obs.turnType == 'answer':\n",
    "            return self.answer_format(obs, guesses)\n",
    "        if obs.turnType == 'guess':\n",
    "            return self.guess_format(obs, guesses)\n",
    "\n",
    "    def similar_guess_format(self, guess):\n",
    "        sim_prompt = (\"You are assisting the game by generating similar keywords to a given keyword. The similar keyword you generate\"\n",
    "                      \"should be either a more specific instance of the keyword, or a thing of a very similar kind as the keyword. Here are some examples:\\n\"\n",
    "                      \"Keyword: Apple. Similar Keyword: Fuji apple\\n\"\n",
    "                      \"Keyword: Ibuprofen. Similar Keyword: Tylenol\\n\"\n",
    "                      \"Keyword: Brownie. Similar Keyword: Fudge brownie\\n\"\n",
    "                      \"Keyword: Polar bear. Similar Keyword: Black bear\\n\"\n",
    "                      \"Keyword: Steel. Similar Keyword: Aluminum\\n\"\n",
    "                      \"Keyword: Curtain. Similar Keyword: Persian blinds\\n\"\n",
    "                      \"Keyword: HDMI cable. Similar Keyword: USB cable\\n\"\n",
    "                      \"Keyword: CPU. Similar Keyword: GPU\\n\"\n",
    "                      \"Keyword: Duck. Similar Keyword: Goose\\n\"\n",
    "                      \"Keyword: Yoga. Similar keyword: Pilates\\n\"\n",
    "                      \"Keyword: Car. Similar keyword: Sedan\\n\"\n",
    "                      \"Keyword: Dumbbell. Similar keyword: Barbell\\n\"\n",
    "                      f\"Now it is your turn. Output ONLY the similar keyword and nothing else, without punctuations.\\n Keyword: {guess}. Similar Keyword:\")\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt+sim_prompt)\n",
    "        return formatted_conversation\n",
    "        \n",
    "    def ask_format(self, obs, guesses):\n",
    "        ask_prompt = (\"You are playing this game as the Questioner. Ask yes-or-no questions that narrow down what the keyword could be. The keyword is a specific thing, NOT a place and NOT a person. \"\n",
    "                      \"DO NOT ask if the keyword is a specific thing, rather ask something about the keyword, as in the following examples:\\n\"\n",
    "                      \"Example 1: Do NOT ask: 'Is the keyword knife?', INSTEAD ask: 'Is it a knife used for a particular purpose?'\\n\"\n",
    "                      \"Example 2: Do NOT ask: 'Is the keyword cow?', INSTEAD ask: 'Is it a specific type or breed of cow?'\\n\"\n",
    "                      \"Example 3: Do NOT ask: 'Is it bottle?', INSTEAD ask: 'Is it a bottle made of a specific material?'\\n\"\n",
    "                      \"Example 4: Do NOT ask: 'Is the keyword lamp?', INSTEAD ask: 'Is it a type of lamp?'\\n\"\n",
    "                      \"Do NOT assume the game has ended, the game will determine when to stop. Instead keep asking questions about the keyword. \"\n",
    "                      \"Do not output any text other than the question. Start with broad questions \"\n",
    "                      \"and based on the answers so far narrow down your questions. Now ask your first question.\\n\\nQuestion: \")\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt + ask_prompt) \n",
    "        for i in range(len(obs.questions)):\n",
    "            formatted_conversation += obs.questions[i] + \"</s>\"\n",
    "            if self.inference_mode or i != len(obs.questions)-1: \n",
    "                formatted_conversation += '\\n' + self.format_instruction(f\"Answer: {obs.answers[i]}\\nAsk your next question. Remember to NOT ask if the keyword is a specific thing, but INSTEAD ask something about the keyword.\\nQuestion:\")  \n",
    "        return formatted_conversation.strip()\n",
    "    \n",
    "    def guess_format(self, obs, guesses):\n",
    "        guess_prompt = \"You are playing this game as the Guesser. After each question and answer you will guess what the keyword is based on the knowledge you have gained \"\\\n",
    "        \"from the questions and answers about the keyword. Do NOT give repeated guesses.\\n\\nRound 1:\\nQuestion: \" + obs.questions[0]+'\\nAnswer: '+ obs.answers[0] +\".\\nNow guess the keyword.\"\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt + guess_prompt) \n",
    "        for i in range(len(guesses)):\n",
    "            formatted_conversation += guesses[i] + \"</s>\"\n",
    "            if self.inference_mode or i < len(guesses)-1: \n",
    "                formatted_conversation += '\\n' + self.format_instruction(f\"Round {i+2}: \\nQuestion: \"+obs.questions[i+1]+\"\\nAnswer: \"+obs.answers[i+1]+\".\\n\"\n",
    "                                                                         \"Now guess the keyword based on the information from all rounds about the keyword. Do not give repeated guesses.\\nGuess:\")  \n",
    "        return formatted_conversation.strip()\n",
    "    \n",
    "    def answer_format(self, obs, guesses):\n",
    "        answer_prompt = \"You are playing this game as the Answerer. You will answer accurately the questions regarding the keyword with ONLY yes or no. \"\\\n",
    "        \"If the questioner did not ask a question, simply answer 'yes'. \"\\\n",
    "        f\"For this game the keyword is {obs.keyword}. Now answer the question about the keyword.\\nKeyword: {obs.keyword}.\\nQuestion: \" + obs.questions[0] +\"\\nAnswer:\"\n",
    "        formatted_conversation = self.format_instruction(self.sys_prompt + answer_prompt) \n",
    "        for i in range(len(obs.answers)):\n",
    "            formatted_conversation += obs.answers[i] + \"</s>\"\n",
    "            if i != len(obs.questions)-1: \n",
    "                formatted_conversation += '\\n' + self.format_instruction(f\"Answer the following question about the keyword.\\nKeyword: {obs.keyword}. \\nQuestion: \" + obs.questions[i+1]+\"\\nAnswer:\")  \n",
    "        return formatted_conversation.strip()\n",
    "    \n",
    "    \n",
    "    def format_response(self, string, string_len, obs):\n",
    "        response = string[string_len+3:]\n",
    "        response = response.replace('</s>', '')\n",
    "        if obs.turnType in ['guess', 'ask']:\n",
    "            return response\n",
    "        else:\n",
    "            response = response.lower()\n",
    "            if 'yes' in response: \n",
    "                return \"yes\"\n",
    "            elif 'no' in response: \n",
    "                return \"no\"\n",
    "            else: \n",
    "                return \"yes\"\n",
    "            \n",
    "    def get_guess_variants(self, guess):\n",
    "        trimmed_string = guess.lstrip()\n",
    "        if not trimmed_string:\n",
    "            return []\n",
    "        if not trimmed_string[0].isalpha():\n",
    "            return []\n",
    "        uppercase_version = trimmed_string.capitalize()\n",
    "        lowercase_version = trimmed_string[0].lower() + trimmed_string[1:]  \n",
    "        return [uppercase_version, lowercase_version]\n",
    "\n",
    "formatter = MistralPromptFormatter(inference_mode = True)\n",
    "\n",
    "\n",
    "#################\n",
    "# Define main function to call model and generate response\n",
    "\n",
    "answer_bad_words = ['maybe', 'sometimes', 'Maybe', 'Sometimes']\n",
    "guess_bad_words = ['answer', 'Answer']\n",
    "guesses = []\n",
    "\n",
    "def get_words_ids(words):\n",
    "    return [tokenizer.encode(word, add_special_tokens=False) for word in words]\n",
    "\n",
    "def tokenize(game_text, tokenizer):\n",
    "    return tokenizer(game_text, return_tensors=\"pt\")\n",
    "\n",
    "def generate_similar_guess(guess):\n",
    "    game_text = formatter.similar_guess_format(guess)\n",
    "    game_text_len = len(game_text)\n",
    "    game_tokens = tokenize(game_text, tokenizer)\n",
    "    output_tokens = model.generate(input_ids=game_tokens[\"input_ids\"].to(\"cuda\"),\n",
    "                                   attention_mask=game_tokens[\"attention_mask\"].to(\"cuda\"),\n",
    "                                   pad_token_id = 2,\n",
    "                                   do_sample = True,\n",
    "                                   temperature = 0.9,\n",
    "                                   top_k = 3,\n",
    "                                   max_new_tokens=16)\n",
    "    output = tokenizer.batch_decode(output_tokens.detach().cpu().numpy(), skip_special_tokens=False)[0]  \n",
    "    response = output[game_text_len+3:]\n",
    "    response = response.replace('</s>', '')\n",
    "    response = response.replace('.','')\n",
    "    return response\n",
    "\n",
    "def generate_response(obs, guesses):\n",
    "    game_text = formatter.format_obs(obs, guesses)\n",
    "    game_text_len = len(game_text)\n",
    "    game_tokens = tokenize(game_text, tokenizer)\n",
    "    output_tokens = model.generate(input_ids=game_tokens[\"input_ids\"].to(\"cuda\"),\n",
    "                                   attention_mask=game_tokens[\"attention_mask\"].to(\"cuda\"),\n",
    "                                   pad_token_id = 2,\n",
    "                                   max_new_tokens=64)\n",
    "    output = tokenizer.batch_decode(output_tokens.detach().cpu().numpy(), skip_special_tokens=False)[0]  \n",
    "    output = formatter.format_response(output, game_text_len, obs) \n",
    "    if obs.turnType == 'guess':\n",
    "        if len(obs.questions) ==1:\n",
    "            if obs.answers[-1] == 'yes':\n",
    "                output = random.choice(['spring roll', 'smoked salmon', 'matcha', 'taco', 'sorbet', 'ravioli', 'knife sharpener', 'wok', 'mayonnaise']).lower()\n",
    "                guesses.append(output)\n",
    "                return output\n",
    "            else:\n",
    "                output = random.choice(['dog leash', 'fountain pen', 'chalk', 'mechanical keyboard', 'jet ski', 'toolbox', 'workbench', 'hammer', 'kimono', 'bicycle', 'loveseat', 'diploma']).lower()\n",
    "                guesses.append(output)\n",
    "                return output\n",
    "        if len(obs.questions) ==2:\n",
    "            if obs.answers[0] == 'yes' and obs.answers[1] == 'yes':\n",
    "                output = random.choice(['spring roll', 'smoked salmon', 'taco', 'sorbet', 'ravioli', 'mayonnaise']).lower()\n",
    "                guesses.append(output)\n",
    "                return output\n",
    "            if obs.answers[0] == 'yes' and obs.answers[1] == 'no':\n",
    "                output = random.choice(['knife sharpener', 'wok', 'chopsticks', 'matcha', 'kombucha', 'dutch oven']).lower()\n",
    "                guesses.append(output)\n",
    "                return output\n",
    "            if obs.answers[0] == 'no' and obs.answers[1] == 'yes':\n",
    "                output = random.choice(['toolbox', 'workbench', 'hammer', 'drone', 'sewing machine']).lower()\n",
    "                guesses.append(output)\n",
    "                return output\n",
    "            else:\n",
    "                output = random.choice(['dog leash', 'fountain pen', 'chalk', 'mechanical keyboard', 'jet ski', 'kimono', 'bicycle', 'loveseat', 'diploma']).lower()\n",
    "                guesses.append(output)\n",
    "                return output\n",
    "        output = output.lower()\n",
    "        attempts = 0\n",
    "        while output in (guesses+OLD_KEYWORDS) and attempts < 4:\n",
    "            output = generate_similar_guess(output).lower()\n",
    "            attempts += 1\n",
    "        guesses.append(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "#################\n",
    "# Function to be called by the game environment\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    \n",
    "    response = generate_response(obs, guesses)\n",
    "    response = response.strip()\n",
    "    \n",
    "    #Catch glitched responses\n",
    "    if (response is None) or (len(response) <= 1) or (len(response) >= 200):\n",
    "        return \"yes\"    \n",
    "    else:\n",
    "        return response\n",
    "    \n",
    "def process_data(data):\n",
    "    obs, cfg = pickle.loads(data)\n",
    "    #print(f\"received obs and cfg\")\n",
    "    result = agent_fn(obs, cfg)\n",
    "    #print(f\"result: {result}\")\n",
    "    return pickle.dumps(result)\n",
    "\n",
    "print(\"Starting server...\")\n",
    "\n",
    "# Set up the server\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n",
    "    try:\n",
    "        server_socket.bind((host, port))\n",
    "        server_socket.listen()\n",
    "        print(f\"Server started, waiting for connection on port {port}...\")\n",
    "        while True:\n",
    "            conn, addr = server_socket.accept()\n",
    "            with conn:\n",
    "                #print(f\"Connected by {addr}\")\n",
    "                data = conn.recv(4096)\n",
    "                if not data:\n",
    "                    break\n",
    "                result = process_data(data)\n",
    "                conn.sendall(result)\n",
    "    except OSError as e:\n",
    "        print(f\"Failed to start server: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5876f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:51:18.003762Z",
     "iopub.status.busy": "2024-08-13T22:51:18.003458Z",
     "iopub.status.idle": "2024-08-13T22:51:25.618136Z",
     "shell.execute_reply": "2024-08-13T22:51:25.617374Z"
    },
    "papermill": {
     "duration": 7.647423,
     "end_time": "2024-08-13T22:51:25.620388",
     "exception": false,
     "start_time": "2024-08-13T22:51:17.972965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pygame installed, ignoring import\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make\n",
    "import kaggle_environments\n",
    "import random\n",
    "\n",
    "def random_agent(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = \"Is it a duck?\"\n",
    "    elif obs.turnType == \"guess\": response = \"duck\"\n",
    "    elif obs.turnType == \"answer\": \n",
    "        random_int = random.randint(0, 1)\n",
    "        if random_int: response = \"Yes\"\n",
    "        else: response = \"No\"\n",
    "    return response\n",
    "\n",
    "class obs(object):\n",
    "    def __init__(self, turnType, keyword, category, questions, answers):\n",
    "        self.turnType = turnType\n",
    "        self.keyword = keyword\n",
    "        self.category = category\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        \n",
    "keyword = \"argentina\"\n",
    "alts = [\"argentina\"]\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.category = \"Place\"\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword_obj = {'keyword':keyword,'alts':alts}\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword = keyword\n",
    "kaggle_environments.envs.llm_20_questions.llm_20_questions.alts = alts\n",
    "\n",
    "env = make(\"llm_20_questions\", debug=True)\n",
    "#game_output = env.run(agents=[\"/tmp/submission/main.py\", random_agent, random_agent, random_agent])\n",
    "#env.render(mode=\"ipython\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481e9ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:51:25.686143Z",
     "iopub.status.busy": "2024-08-13T22:51:25.685656Z",
     "iopub.status.idle": "2024-08-13T22:51:32.195507Z",
     "shell.execute_reply": "2024-08-13T22:51:32.194349Z"
    },
    "papermill": {
     "duration": 6.544204,
     "end_time": "2024-08-13T22:51:32.197730",
     "exception": false,
     "start_time": "2024-08-13T22:51:25.653526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!apt install pigz pv > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ffcd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:51:32.260217Z",
     "iopub.status.busy": "2024-08-13T22:51:32.259383Z",
     "iopub.status.idle": "2024-08-13T22:54:49.445519Z",
     "shell.execute_reply": "2024-08-13T22:54:49.444388Z"
    },
    "papermill": {
     "duration": 197.219103,
     "end_time": "2024-08-13T22:54:49.447838",
     "exception": false,
     "start_time": "2024-08-13T22:51:32.228735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf /kaggle/working/submission.tar.gz -C /tmp/submission ."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 81882,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 95155,
     "modelInstanceId": 70048,
     "sourceId": 83386,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 96205,
     "modelInstanceId": 71206,
     "sourceId": 84765,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 88403,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 91014,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 92640,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 93085,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 93962,
     "modelInstanceId": 68810,
     "sourceId": 94328,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 411.371511,
   "end_time": "2024-08-13T22:54:51.976121",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-13T22:48:00.604610",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
